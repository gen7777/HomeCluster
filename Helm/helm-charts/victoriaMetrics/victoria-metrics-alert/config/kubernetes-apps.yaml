groups:
- name: kubernetes-apps.rules
  rules:
  #1 Pod находится в CrashLoop, что означает, что приложение умирает или не отвечает, и kubernetes пытается перезапустить его автоматически.
  - alert: KubePodCrashLooping
    expr: max_over_time(kube_pod_container_status_waiting_reason{job="kube-state-metrics",namespace=~".*",reason="CrashLoopBackOff"}[5m]) >= 1
    for: 15m
    labels:
      severity: warning
    annotations:
      description: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state reason "CrashLoopBackOff".
      summary: Pod is crash looping.

  #2 Pod находился в не готовом состоянии более 15 минут.
  - alert: KubePodNotReady
    expr: sum by (namespace, pod, datacenter) (max by (namespace, pod, datacenter) (kube_pod_status_phase{job="kube-state-metrics",namespace=~".*",phase=~"Pending|Unknown|Failed"}) * on (namespace, pod, datacenter) group_left (owner_kind) topk by (namespace, pod, datacenter) (1, max by (namespace, pod, owner_kind, datacenter) (kube_pod_owner{owner_kind!="Job"}))) > 0
    for: 15m
    labels:
      severity: warning
    annotations:
      description: В {{ $labels.datacentr }} Pod {{ $labels.namespace }}/{{ $labels.pod }} находился в не готовом состоянии более 15 минут..
      summary: Pod находился в не готовом состоянии более 15 минут.

  #3 Несоответствие генерации Deployment из-за возможного отката.
  - alert: KubeDeploymentGenerationMismatch
    expr: kube_deployment_status_observed_generation{job="kube-state-metrics",namespace=~".*"} != kube_deployment_metadata_generation{job="kube-state-metrics",namespace=~".*"}
    for: 15m
    labels:
      severity: warning
    annotations:
      description: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back.
      summary: Deployment generation mismatch due to possible roll-back

  #4 Deployment не соответствует ожидаемому количеству копий
  - alert: KubeDeploymentReplicasMismatch
    expr: (kube_deployment_spec_replicas{job="kube-state-metrics",namespace=~".*"} > kube_deployment_status_replicas_available{job="kube-state-metrics",namespace=~".*"}) and (changes(kube_deployment_status_replicas_updated{job="kube-state-metrics",namespace=~".*"}[10m]) == 0)
    for: 15m
    labels:
      severity: warning
    annotations:
      description: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes.
      summary: Deployment has not matched the expected number of replicas.

  #5 StatefulSet не соответствует ожидаемому количеству копий. (из-за этого правила не стартовал victoria-alert)
  - alert: KubeStatefulSetReplicasMismatch
    expr: (kube_statefulset_status_replicas_ready{job="kube-state-metrics",namespace=~".*"} != kube_statefulset_status_replicas{job="kube-state-metrics",namespace=~".*"}) and (changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics",namespace=~".*"}[10m]) == 0)
    for: 15m
    labels:
      severity: warning
    annotations:
      description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes.
      summary: Deployment has not matched the expected number of replicas.

  #6 Несоответствие генерации StatefulSet из-за возможного отката.
  - alert: KubeStatefulSetGenerationMismatch
    expr: kube_statefulset_status_observed_generation{job="kube-state-metrics",namespace=~".*"} != kube_statefulset_metadata_generation{job="kube-state-metrics",namespace=~".*"}
    for: 15m
    labels:
      severity: warning
    annotations:
      description: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back.
      summary: StatefulSet generation mismatch due to possible roll-back

 #7 Обновление StatefulSet не было развернуто.
  - alert: KubeStatefulSetUpdateNotRolledOut
    expr: (max without (revision) (kube_statefulset_status_current_revision{job="kube-state-metrics",namespace=~".*"} unless kube_statefulset_status_update_revision{job="kube-state-metrics",namespace=~".*"}) * (kube_statefulset_replicas{job="kube-state-metrics",namespace=~".*"} != kube_statefulset_status_replicas_updated{job="kube-state-metrics",namespace=~".*"})) and (changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics",namespace=~".*"}[5m]) == 0)
    for: 15m
    labels:
      severity: warning
    annotations:
      description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.
      summary: StatefulSet update has not been rolled out.
      
#8 Обновление DaemonSet застряло в ожидании замены модуля.
  - alert: KubeDaemonSetRolloutStuck
    expr: (
            (kube_daemonset_status_current_number_scheduled{daemonset!="speaker",job="kube-state-metrics",namespace=~".*"} !=
            kube_daemonset_status_desired_number_scheduled{daemonset!="speaker",job="kube-state-metrics",namespace=~".*"})
          or (kube_daemonset_status_number_misscheduled{daemonset!="speaker",job="kube-state-metrics",namespace=~".*"} != 0)
          or (kube_daemonset_status_updated_number_scheduled{daemonset!="speaker",job="kube-state-metrics",namespace=~".*"} !=
            kube_daemonset_status_desired_number_scheduled{daemonset!="speaker",job="kube-state-metrics",namespace=~".*"})
          or (kube_daemonset_status_number_available{daemonset!="speaker",job="kube-state-metrics",namespace=~".*"} !=
            kube_daemonset_status_desired_number_scheduled{daemonset!="speaker",job="kube-state-metrics",namespace=~".*"})
          ) and (changes(kube_daemonset_status_updated_number_scheduled{daemonset!="speaker",job="kube-state-metrics",namespace=~".*"}[5m]) == 0)
    for: 15m
    labels:
      severity: warning
    annotations:
      description: DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15 minutes.
      summary: DaemonSet rollout is stuck.

#9 Контейнер в Pod слишком долго находится в состоянии ожидания.
  - alert: KubeContainerWaiting
    expr: sum by (namespace, pod, container, datacenter) (kube_pod_container_status_waiting_reason{job="kube-state-metrics",namespace=~".*"}) > 0
    for: 1h
    labels:
      severity: warning
    annotations:
      description: pod/{{ $labels.pod }} in namespace {{ $labels.namespace }} on container {{ $labels.container}} has been in waiting state for longer than 1 hour.
      summary: Pod container waiting longer than 1 hour

#10 Несколько(ряд) Pods в demonset не запланированны
  - alert: KubeDaemonSetNotScheduled
    expr: kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics",namespace=~".*"} - kube_daemonset_status_current_number_scheduled{job="kube-state-metrics",namespace=~".*"} > 0
    for: 10m
    labels:
      severity: warning
    annotations:
      description: Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled.
      summary: DaemonSet pods are not scheduled.

 #11 Ряд Pods в  demonset работает там, где они не должны быть
  - alert: KubeDaemonSetMisScheduled
    expr: kube_daemonset_status_number_misscheduled{daemonset!="speaker",job="kube-state-metrics",namespace=~".*"} > 0
    for: 15m
    labels:
      severity: warning
    annotations:
      description:  ПОДы DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} Работают там, где не должны быть запущены.
      summary: Неверное размещение в DaemonSet.

 #12 Ряд Pods в  demonset работает там, где они не должны быть
  - alert: KubeJobNotCompleted
    expr: time() - max by (namespace, job_name, datacenter) (kube_job_status_start_time{job="kube-state-metrics",daemonset!="speaker", namespace=~".*"} and kube_job_status_active{job="kube-state-metrics",daemonset!="speaker", namespace=~".*"} > 0) > 43200
    labels:
      severity: warning
    annotations:
      description: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than {{ "43200" | humanizeDuration }} to complete.
      summary: Job did not complete in time

 #13 Ряд Pods в  demonset работает там, где они не должны быть
  - alert: KubeJobFailed
    expr: kube_job_failed{job="kube-state-metrics",namespace=~".*"} > 0
    for: 15m
    labels:
      severity: warning
    annotations:
      description: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert.
      summary: Job failed to complete.

#14 Горизонтальный Pod Autoscaler не соответствует желаемому количеству копий дольше 15 минут.
  - alert: KubeHpaReplicasMismatch
    expr: (kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics",namespace=~".*"} != kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"}) and (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"} > kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics",namespace=~".*"}) and (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"} < kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics",namespace=~".*"}) and changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"}[15m]) == 0
    for: 15m
    labels:
      severity: warning
    annotations:
      description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} has not matched the desired number of replicas for longer than 15 minutes.
      runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubehpareplicasmismatch
      summary: HPA has not matched desired number of replicas.

#15 Горизонтальный Pod Autoscaler работает на максимальных репликах более 15 минут
  - alert: KubeHpaMaxedOut
    expr: kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"} == kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics",namespace=~".*"}
    for: 15m
    labels:
      severity: warning
    annotations:
      description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} has been running at max replicas for longer than 15 minutes.
      summary: HPA is running at max replicas